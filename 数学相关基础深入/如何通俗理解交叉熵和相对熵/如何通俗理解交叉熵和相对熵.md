参考一：如何通俗的解释交叉熵与相对熵? - CyberRep的回答 - 知乎
https://www.zhihu.com/question/41252833/answer/195901726

参考二：摘自《神经网络与深度学习》
在信息论领域是有一种标准方式来解释交叉熵的。大致说来，想法就是：交叉熵是对「出乎意料」（译者注：原文使用suprise）的度量。
交叉熵衡量的是我们在知道 y 的真实值时的平均「出乎意料」程度。当输出是我们期望的值，我们的「出乎意料」程度比较低；当输出不是我们期望的，我们的「出乎意料」程度就比较高。当然，我没有准确说明「出乎意料」是什么意思，所以这个措辞听起来很空洞。但事实上是有一种精确的信息理论方法来阐述「出乎意料」所表达的意思的。不幸的是，我并不知晓网络上是否能够找到有关该主题的出色、简短、自洽的讨论。但是如果你想深究下去，维基百科上有一个能让你正确入门的[简要概述](http://en.wikipedia.org/wiki/Cross_entropy#Motivation)。细节部分可通过研读有关Kraft不等式的材料来补充，这些材料在[Cover and Thomas](http://books.google.ca/books?id=VWq5GG6ycxMC)所写的有关信息论的书籍的第五章中可以找到。

参考三：
交叉熵：用来高衡量在给定的真实分布下，使用非真实分布指定的策略消除系统的不确定性所需要付出努力的大小。

